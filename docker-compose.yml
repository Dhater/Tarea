services:
  clean:
    image: busybox
    volumes:
      - ./Filtro/data:/data
    command: sh -c "rm -rf /data/output/analisis /data/output/filtrados /data/output/por_ciudad /data/output/por_tipo /data/output/por_fecha /data/input/eventos.csv"
  scraper:
    build: ./scraper
    container_name: scraper
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=mi_basededatos
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=user
      - REDIS_HOST=redis
      - PYTHONUNBUFFERED=1
    networks:
      - red_scraper
    volumes:
      - ./scraper:/app
      - /app/venv
      - ./Filtro/data/input:/csv

  postgres:
    image: postgres:16
    container_name: postgres
    environment:
      - POSTGRES_DB=mi_basededatos
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=user
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - red_scraper
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d mi_basededatos"]
      interval: 5s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7
    container_name: redis
    volumes:
      - redis_data:/data
    networks:
      - red_scraper
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s

  cache_service:
    build: ./cache_service
    environment:
      - REDIS_HOST=redis
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=mi_basededatos
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=user
      - PYTHONUNBUFFERED=1
    container_name: cache_service
    ports:
      - "5000:5000"
    networks:
      - red_scraper
    volumes:
      - ./cache_service:/app
      - /app/venv
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 10s
      timeout: 5s
      retries: 3

  trafico:
    build: ./trafico
    container_name: trafico
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=mi_basededatos
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=user
      - CACHE_SERVICE_URL=http://cache_service:5000
      - PYTHONUNBUFFERED=1
    networks:
      - red_scraper
    volumes:
      - ./trafico:/app
      - /app/venv
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 10s
      retries: 5
      start_period: 30s
      timeout: 5s

  filtro-hadoop:
    build: ./Filtro
    container_name: filtro-hadoop
    ports:
      - "9870:9870"
      - "8088:8088"
      - "22:22"
    volumes:
      - ./Filtro/scripts:/pig/scripts
      - ./Filtro/data:/pig/data
      - ./Filtro/data/input:/pig/input
      - ./Filtro/data/output:/pig/output   # <-- AquÃ­ agregas para persistir la salida localmente
    command: sh -c "sleep 20 && sh /pig/scripts/start.sh"
    networks:
      - red_scraper
    depends_on:
      - postgres
      - redis
    healthcheck:
      test: ["CMD", "hdfs", "dfsadmin", "-report"]
      interval: 30s
      timeout: 10s
      retries: 3
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.4
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - xpack.security.transport.ssl.enabled=false
      - bootstrap.memory_lock=true
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - es_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - red_scraper
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200 || exit 1"]
      interval: 20s
      timeout: 10s
      retries: 3

  kibana:
    image: docker.elastic.co/kibana/kibana:8.13.4
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - red_scraper
  indexer:
    build: ./indexer
    container_name: indexer
    depends_on:
      - elasticsearch
    volumes:
      - ./Filtro/data:/data   # monta el volumen con los datos Pig
    networks:
      - red_scraper

 
networks:
  red_scraper:

volumes:
  redis_data:
  postgres_data:
  es_data:
